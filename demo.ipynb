{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# edit the config\n",
    "device = torch.device('cuda:2')\n",
    "torch.cuda.set_device(2)\n",
    "dataset_name = 'lsa' # ['vox', 'taichi', 'ted', 'mgif']\n",
    "# source_image_path = '/DataSet/lsa64_cut/test/057_001_005/057_001_005_000.png'\n",
    "# source_image_path = '/DataSet/LSA64/256/test/057_001_005/057_001_005_000.png'\n",
    "# source_image_path = '/DataSet/PHOENIX-2014-T/features/fullFrame-128x128px/test/11August_2009_Tuesday_tagesschau-4355/images0001.png'\n",
    "# source_image_path = '/DataSet/WLASL2000_128x128/test/03089/0001.png'\n",
    "# source_image_path = '/disk1/dataset/PHOENIX-2014-T-release-v3/PHOENIX-2014-T/features/fullFrame-128x128px/test/01May_2010_Saturday_tagesschau-7195/images0001.png'\n",
    "# # csl\n",
    "# source_image_path = '/disk1/dataset/CSL-Daily_128x128px/test/S000054_P0008_T00/000017.jpg'\n",
    "# driving_folder_path = '/disk1/dataset/CSL-Daily_128x128px/test/S000153_P0000_T00'\n",
    "# driving_folder_path = '/disk1/dataset/CSL-Daily_128x128px/test/S000020_P0004_T00'\n",
    "# driving_folder_path = '/disk1/dataset/CSL-Daily_128x128px/test/S005971_P0006_T00'\n",
    "# driving_folder_path = '/disk1/dataset/CSL-Daily_128x128px/test/S007121_P0007_T00'\n",
    "\n",
    "# p14t\n",
    "source_image_path = '/disk1/dataset/PHOENIX-2014-T-release-v3/PHOENIX-2014-T/features/fullFrame-128x128px/test/05May_2011_Thursday_heute-3747/images0008.png'\n",
    "driving_folder_path = '/disk1/dataset/PHOENIX-2014-T-release-v3/PHOENIX-2014-T/features/fullFrame-128x128px/test/29April_2010_Thursday_heute-8626'\n",
    "# driving_folder_path = '/disk1/dataset/PHOENIX-2014-T-release-v3/PHOENIX-2014-T/features/fullFrame-128x128px/test/01April_2010_Thursday_tagesschau-4330'\n",
    "# driving_folder_path = '/disk1/dataset/PHOENIX-2014-T-release-v3/PHOENIX-2014-T/features/fullFrame-128x128px/test/01December_2011_Thursday_tagesschau-3473'\n",
    "# driving_folder_path = '/disk1/dataset/PHOENIX-2014-T-release-v3/PHOENIX-2014-T/features/fullFrame-128x128px/test/02December_2010_Thursday_tagesschau-3631'\n",
    "\n",
    "dir_name = os.path.basename(driving_folder_path)\n",
    "output_video_path = './'+dir_name+'.mp4'\n",
    "config_path = 'config/wlasl.yaml'\n",
    "checkpoint_path = '/disk1/tongkai/mraa/log/phoenix.pth.tar'\n",
    "predict_mode = 'standard' # ['standard', 'relative', 'avd']\n",
    "find_best_frame = False # when use the relative mode to animate a face, use 'find_best_frame=True' can get better quality result\n",
    "\n",
    "pixel = 128 # for vox, taichi and mgif, the resolution is 256*256\n",
    "if(dataset_name == 'ted'): # for ted, the resolution is 384*384\n",
    "    pixel = 384\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Driving Video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import imageio\n",
    "\n",
    "# folder_path = driving_folder_path\n",
    "# image_files = [os.path.join(folder_path, file) for file in sorted(os.listdir(folder_path)) if file.endswith('.png')]\n",
    "# writer = imageio.get_writer(driving_video_path, fps=30)\n",
    "\n",
    "# for image_file in image_files:\n",
    "#     image = imageio.imread(image_file)\n",
    "#     writer.append_data(image)\n",
    "\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read image and video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "Oxi6-riLOgnm",
    "outputId": "d38a8850-9eb1-4de4-9bf2-24cbd847ca1f"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from skimage.transform import resize\n",
    "from IPython.display import HTML\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "source_image = imageio.imread(source_image_path)\n",
    "\n",
    "image_files = [os.path.join(driving_folder_path, file) for file in sorted(os.listdir(driving_folder_path)) if (file.endswith('.png') or file.endswith('.jpg'))]\n",
    "fps = 30\n",
    "driving_video = []\n",
    "\n",
    "for image_file in image_files:\n",
    "    image = imageio.imread(image_file)\n",
    "    driving_video.append(image)\n",
    "\n",
    "source_image = resize(source_image, (pixel, pixel))[..., :3]\n",
    "\n",
    "driving_video = [resize(frame, (pixel, pixel))[..., :3] for frame in driving_video]\n",
    "\n",
    "def display(source, driving, generated=None):\n",
    "    fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6))\n",
    "\n",
    "    ims = []\n",
    "    for i in range(len(driving)):\n",
    "        cols = [source]\n",
    "        cols.append(driving[i])\n",
    "        if generated is not None:\n",
    "            cols.append(generated[i])\n",
    "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
    "        plt.axis('off')\n",
    "        ims.append([im])\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n",
    "    plt.close()\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjM7ubVfWrwT"
   },
   "source": [
    "**Create a model and load checkpoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "3FQiXqQPWt5B"
   },
   "outputs": [],
   "source": [
    "from demo import load_checkpoints\n",
    "inpainting, dense_motion_network, bg_predictor = load_checkpoints(config_path = config_path, checkpoint_path = checkpoint_path, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdFdasHEj3t7"
   },
   "source": [
    "**Perform image animation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "id": "SB12II11kF4c",
    "outputId": "9e2274aa-fd55-4eed-cb50-bec72fcfb8b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:00<00:00, 83.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from demo import make_animation\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "predictions = make_animation(source_image, driving_video, inpainting, dense_motion_network, bg_predictor, device = device, mode = predict_mode)\n",
    "\n",
    "#save resulting video\n",
    "imageio.mimsave(output_video_path, [img_as_ubyte(frame) for frame in predictions], fps=fps)\n",
    "\n",
    "# HTML(display(source_image, driving_video, predictions).to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from demo import inference_img\n",
    "# import imageio\n",
    "# from skimage.transform import resize\n",
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "\n",
    "# torch.cuda.set_device(5)\n",
    "# device = torch.device('cuda:5')\n",
    "\n",
    "# source_image_path = '/disk1/dataset/WLASL2000_128x128/test/69494/0040.png'\n",
    "# driving_image_path = '/disk1/dataset/WLASL2000_128x128/test/01248/0006.png'\n",
    "# config_path = 'config/wlasl.yaml'\n",
    "# checkpoint_path = 'log/wlasl.pth.tar'\n",
    "# out_img_path = driving_image_path.split('/')[-2]+'_'+driving_image_path.split('/')[-1]\n",
    "\n",
    "\n",
    "# source_image = imageio.imread(source_image_path)\n",
    "# source_image = resize(source_image, (128, 128))[..., :3]\n",
    "\n",
    "# driving_image = imageio.imread(driving_image_path)\n",
    "# driving_image = resize(driving_image, (128, 128))[..., :3]\n",
    "\n",
    "# from demo import load_checkpoints\n",
    "# inpainting, dense_motion_network, bg_predictor = load_checkpoints(config_path = config_path, checkpoint_path = checkpoint_path, device = device)\n",
    "\n",
    "# out = inference_img(source_image, driving_image, inpainting, dense_motion_network, bg_predictor, device)\n",
    "# prediction = out['prediction'][0].cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "# imageio.imsave(out_img_path, (255 * prediction).astype(np.uint8))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "first-order-model-demo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
